{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr\n",
    "import cv2\n",
    "\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "image_path = 'outputs/2024_1126_150000F_trimmed/object_detection/cropped_vessel_imgs/2024_1126_150000F_trimmed_cropped_vessel_id_1_frame_79.png'\n",
    "image = cv2.imread(image_path).resize(300,300)\n",
    "\n",
    "results = pipeline.recognize(image)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\dbacad\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\dbacad\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "import keras_ocr\n",
    "import cv2\n",
    "\n",
    "# Initialize Keras-OCR pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Load and preprocess image\n",
    "image = cv2.imread(image_path)\n",
    "resized_image = cv2.resize(image, (800, 600))\n",
    "grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "_, binary_image = cv2.threshold(grayscale_image, 128, 255, cv2.THRESH_BINARY)\n",
    "processed_image = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Adjust detection thresholds\n",
    "pipeline.detector.detection_threshold = 0.8\n",
    "pipeline.detector.text_threshold = 0.5\n",
    "pipeline.detector.link_threshold = 0.5\n",
    "\n",
    "# Perform OCR\n",
    "results = pipeline.recognize([processed_image])\n",
    "\n",
    "# Print detected text\n",
    "for text, box in results[0]:\n",
    "    print(f\"Detected text: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 11 13:06:25 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 538.27                 Driver Version: 538.27       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX 2000 Ada Gene...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   48C    P4              10W /  30W |      0MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# TRY RETINA MASK ARGUMENT!\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n",
      "NVIDIA RTX 2000 Ada Generation Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.version.cuda)  # Should return '12.2'\n",
    "print(torch.cuda.get_device_name(0))  # Should display your GPU name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.cudnn.is_available())  # Should return True\n",
    "print(torch.backends.cudnn.version())  # Should return the installed cuDNN version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from scipy.ndimage import center_of_mass\n",
    "from src.third_party.depth_anything_v2.dpt import DepthAnythingV2\n",
    "from ultralytics import YOLO\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = \"2024_1126_150000F_trimmed_vessel_detected_shot_id_1_frame_79.png\" \n",
    "input_image_name = input_image.split(\".png\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection using YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1088x1920 1 person, 5 boats, 252.4ms\n",
      "Speed: 0.0ms preprocess, 252.4ms inference, 2.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "Highest confidence for a boat: 0.8599649667739868\n"
     ]
    }
   ],
   "source": [
    "# Load YOLO model (We're using YOLO 11 XL for segmentation model for the masks)\n",
    "model_name = \"yolo11x-seg\"\n",
    "model = YOLO(f\"./yolo_weights/{model_name}.pt\")\n",
    "\n",
    "# Run object detection\n",
    "results = model([f\"outputs/2024_1126_150000F_trimmed/tracked_vessels/2024_1126_150000F_trimmed_vessel_detected_shot_id_1_frame_79.png\"], imgsz=1920, conf=0.2)\n",
    "\n",
    "# View results\n",
    "for r in results:\n",
    "    r.save(filename=f\"_{model_name}_{input_image_name}.jpg\")  # save to disk\n",
    "\n",
    "# Filter for boats\n",
    "boat_class_id = next(k for k, v in model.names.items() if v.lower() == \"boat\")\n",
    "\n",
    "for r in results:\n",
    "    # Extract masks, class IDs, and confidence scores\n",
    "    if r.masks is not None and r.boxes is not None:\n",
    "        masks = r.masks.data.cpu().numpy()  # Shape: (N, H, W)\n",
    "        class_ids = r.boxes.cls.cpu().numpy()  # Class IDs for masks\n",
    "        confidences = r.boxes.conf.cpu().numpy()  # Confidence scores for masks\n",
    "\n",
    "        # Filter indices for the 'boat' class\n",
    "        boat_indices = np.where(class_ids == boat_class_id)[0]\n",
    "\n",
    "        if len(boat_indices) > 0:\n",
    "            # Find the boat with the highest confidence score\n",
    "            highest_conf_index = boat_indices[np.argmax(confidences[boat_indices])]\n",
    "            boat_mask = masks[highest_conf_index]  # Binary mask for the boat with highest confidence\n",
    "            highest_confidence = confidences[highest_conf_index]\n",
    "\n",
    "            print(f\"Highest confidence for a boat: {highest_confidence}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved arrays\n",
    "boat_mask = np.load('./outputs/2024_1126_143639F_trimmed/object_detection/mask_arrays/2024_1126_143639F_trimmed_mask_array_id_1_frame_355.npy')\n",
    "depth = np.load('./outputs/2024_1126_143639F_trimmed/depth_estimation/depth_arrays/2024_1126_143639F_trimmed_depth_array_id_1_frame_355.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n",
      "(1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "print(depth.shape)\n",
    "print(boat_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth Estimation using DepthAnythingV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prereq to download the vitl weights and save it in the checkpoints folder inside the third_party folder\n",
    "# We're just using the large version\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "\n",
    "encoder = 'vitl' # or 'vits', 'vitb', 'vitg'\n",
    "\n",
    "model = DepthAnythingV2(**model_configs[encoder])\n",
    "# model.load_state_dict(torch.load(f'checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu')) Original code but were utilizing depth-anything as a submodule/third-party\n",
    "model.load_state_dict(torch.load(f'src/third_party/checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu')) \n",
    "\n",
    "# raw_img = cv2.imread(f'data/tracked_vessels/{input_image}')\n",
    "raw_img = cv2.imread(f'outputs/2024_1126_143639F_trimmed/tracked_vessels/2024_1126_143639F_trimmed_vessel_detected_shot_id_1_frame_355.png')\n",
    "depth = model.infer_image(raw_img) # HxW raw depth map in numpy\n",
    "\n",
    "# Save array:\n",
    "input_image_name = input_image.split(\".png\")[0]\n",
    "#np.savetxt(f\"{input_image_name}.txt\", depth, fmt=\"%.5f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boat center: (1312.809682878052, 623.4211370678856)\n",
      "Boat height (pixels): 135\n"
     ]
    }
   ],
   "source": [
    "# Find the center of the boat\n",
    "center_y, center_x = center_of_mass(boat_mask)  # Center in (y, x) format\n",
    "\n",
    "# Measure the height in pixels\n",
    "rows, _ = np.where(boat_mask > 0)\n",
    "boat_height_pixels = np.max(rows) - np.min(rows)\n",
    "\n",
    "print(f\"Boat center: ({center_x}, {center_y})\")\n",
    "print(f\"Boat height (pixels): {boat_height_pixels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        ...,\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0]],\n",
       "\n",
       "       [[128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        ...,\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0]],\n",
       "\n",
       "       [[128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        ...,\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0],\n",
       "        [128,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0, 252, 255],\n",
       "        [  0, 252, 255],\n",
       "        [  0, 252, 255],\n",
       "        ...,\n",
       "        [174, 255,  82],\n",
       "        [174, 255,  82],\n",
       "        [174, 255,  82]],\n",
       "\n",
       "       [[  0, 252, 255],\n",
       "        [  0, 252, 255],\n",
       "        [  0, 252, 255],\n",
       "        ...,\n",
       "        [174, 255,  82],\n",
       "        [174, 255,  82],\n",
       "        [174, 255,  82]],\n",
       "\n",
       "       [[  0, 252, 255],\n",
       "        [  0, 252, 255],\n",
       "        [  0, 252, 255],\n",
       "        ...,\n",
       "        [170, 255,  86],\n",
       "        [170, 255,  86],\n",
       "        [170, 255,  86]]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize depth map\n",
    "depth_normalized = (depth - depth.min()) / (depth.max() - depth.min()) * 255\n",
    "depth_colored = cv2.applyColorMap(depth_normalized.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "depth_resized = cv2.resize(depth_colored, (boat_mask.shape[1], boat_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Overlay the mask onto the depth map visualization\n",
    "boat_overlay = depth_resized.copy()\n",
    "boat_overlay[boat_mask > 0] = [0, 255, 0]  # Green for the boat mask\n",
    "\n",
    "# Annotate the image with the center and height\n",
    "cv2.circle(boat_overlay, (int(center_x), int(center_y)), 5, (255, 0, 0), -1)  # Mark center in red\n",
    "cv2.putText(\n",
    "    boat_overlay,\n",
    "    f\"Height: {boat_height_pixels}px\",\n",
    "    (int(center_x) - 50, int(center_y) - 20),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    0.6,\n",
    "    (255, 255, 255),\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth at boat center: 36.05406188964844\n",
      "Average boat depth: 33.786720275878906\n"
     ]
    }
   ],
   "source": [
    "# Resize the depth map to match the boat_mask dimensions\n",
    "depth_resized = cv2.resize(depth_normalized, (boat_mask.shape[1], boat_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Convert boat_mask to boolean\n",
    "boat_mask_boolean = boat_mask > 0  # Ensure the mask is boolean (True/False)\n",
    "\n",
    "# Calculate rows_with_mask using the original mask\n",
    "rows_with_mask = np.any(boat_mask_boolean, axis=1)\n",
    "\n",
    "# Get the depth values corresponding to the mask\n",
    "boat_depth_values = depth_resized[rows_with_mask, :]\n",
    "boat_depth_average = boat_depth_values[boat_mask_boolean[rows_with_mask, :]].mean()\n",
    "\n",
    "# Get the depth at the boat center\n",
    "boat_center_depth = depth_resized[int(center_y), int(center_x)]\n",
    "\n",
    "print(f\"Depth at boat center: {boat_center_depth}\")\n",
    "print(f\"Average boat depth: {boat_depth_average}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the combined visualization\n",
    "cv2.imwrite(f\"{input_image}.png\", boat_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO processed mask shape: (1080, 1920)\n",
      "Original image shape: (1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "print(f\"YOLO processed mask shape: {boat_mask.shape}\")  # e.g., (1216, 2112)\n",
    "print(f\"Original image shape: {depth.shape}\")  # e.g., (1183, 2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth at boat center: 36.05406188964844\n"
     ]
    }
   ],
   "source": [
    "# Get the depth at the center of the boat\n",
    "boat_center_depth = depth_resized[int(center_y), int(center_x)]\n",
    "print(f\"Depth at boat center: {boat_center_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average depth in the rectangle: 227.80648803710938\n"
     ]
    }
   ],
   "source": [
    "# Define the top-left and bottom-right coordinates of the rectangular area\n",
    "rect_top_left_x = 1085 # X-coordinate of the top-left corner\n",
    "rect_top_left_y = 637  # Y-coordinate of the top-left corner\n",
    "rect_bottom_right_x = 1097   # X-coordinate of the bottom-right corner\n",
    "rect_bottom_right_y = 708  # Y-coordinate of the bottom-right corner\n",
    "\n",
    "# Extract the depth values within the rectangle\n",
    "rect_depth_values = depth_resized[\n",
    "    rect_top_left_y:rect_bottom_right_y,\n",
    "    rect_top_left_x:rect_bottom_right_x\n",
    "]\n",
    "\n",
    "# Calculate the average depth within the rectangle\n",
    "rect_depth_average = rect_depth_values.max()\n",
    "\n",
    "# Print the average depth\n",
    "print(f\"Average depth in the rectangle: {rect_depth_average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_orange_rect_px = 71\n",
    "h_meter_stick_px = 200\n",
    "h_meter_stick_actual = 1\n",
    "h_orange_rect_actual = h_orange_rect_px/h_meter_stick_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.355"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_orange_rect_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.551178041830483"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OG ( ORANGE RECTANGLE )\n",
    "135*(0.355/71)*(227.80648803710938/33.786720275878906)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1971788176455147"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JUST RULER\n",
    "128*(1/598)*(28.99/31.47)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vhe_gpu_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
