{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from src.third_party.depth_anything_v2.dpt import DepthAnythingV2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "image_path = 'outputs/2024_1126_143639F_trimmed/tracked_vessels/2024_1126_143639F_trimmed_vessel_detected_shot_id_1_frame_355.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Height Estimation of Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse clicked at: (1112, 673)\n",
      "Mouse clicked at: (1128, 745)\n",
      "Clicked coordinates: [(1112, 673), (1128, 745)]\n",
      "Orange Area Height in Pixels: 72\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the coordinates\n",
    "coordinates = []\n",
    "\n",
    "def get_coordinates(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Store the coordinates\n",
    "        coordinates.append((x, y))\n",
    "        print(f\"Mouse clicked at: ({x}, {y})\")\n",
    "\n",
    "# Specify the rotation angle in degrees (counterclockwise)\n",
    "rotation_angle = 2.5  # Replace with desired angle\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image.\")\n",
    "    exit()\n",
    "\n",
    "# Get image dimensions\n",
    "image_height, image_width = image.shape[:2]\n",
    "\n",
    "# Calculate the center of the image for rotation\n",
    "center = (image_width // 2, image_height // 2)\n",
    "\n",
    "# Compute the rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "\n",
    "# Determine the new bounding dimensions of the image after rotation\n",
    "cos = abs(rotation_matrix[0, 0])\n",
    "sin = abs(rotation_matrix[0, 1])\n",
    "new_width = int((image_height * sin) + (image_width * cos))\n",
    "new_height = int((image_height * cos) + (image_width * sin))\n",
    "\n",
    "# Adjust the rotation matrix to account for translation\n",
    "rotation_matrix[0, 2] += (new_width / 2) - center[0]\n",
    "rotation_matrix[1, 2] += (new_height / 2) - center[1]\n",
    "\n",
    "# Rotate the image\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (new_width, new_height))\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.namedWindow('Rotated Image')\n",
    "cv2.setMouseCallback('Rotated Image', get_coordinates)\n",
    "\n",
    "# Display the rotated image\n",
    "while True:\n",
    "    cv2.imshow('Rotated Image', rotated_image)\n",
    "    \n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print the clicked coordinates\n",
    "print(\"Clicked coordinates:\", coordinates)\n",
    "print(f\"Orange Area Height in Pixels: {coordinates[1][1] - coordinates[0][1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth Estimation of Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange Area Depth: 230\n"
     ]
    }
   ],
   "source": [
    "# Determine device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# Model configurations\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "\n",
    "encoder = 'vitl'\n",
    "model = DepthAnythingV2(**model_configs[encoder])\n",
    "model.load_state_dict(torch.load(f'src/third_party/checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "\n",
    "raw_img = cv2.imread(image_path)\n",
    "\n",
    "# Rotate for better measurement of height\n",
    "rotation_angle = 2.5  # Counterclockwise rotation in degrees\n",
    "center = (raw_img.shape[1] // 2, raw_img.shape[0] // 2)  # Image center\n",
    "scale = 1.0  # No scaling\n",
    "\n",
    "# Compute the rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, scale)\n",
    "\n",
    "# Perform the rotation\n",
    "rotated_img = cv2.warpAffine(raw_img, rotation_matrix, (raw_img.shape[1], raw_img.shape[0]))\n",
    "depth = model.infer_image(rotated_img)\n",
    "\n",
    "# Normalize depth map\n",
    "depth_normalized = (depth - depth.min()) / (depth.max() - depth.min()) * 255\n",
    "depth_normalized = depth_normalized.astype(np.uint8)\n",
    "\n",
    "# Apply a colormap to the depth map\n",
    "depth_colormap = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)\n",
    "\n",
    "# Overlay the colormap on the original rotated image\n",
    "overlay = cv2.addWeighted(rotated_img, 0.6, depth_colormap, 0.4, 0)\n",
    "\n",
    "# Define the top-left and bottom-right coordinates of the rectangular area\n",
    "ruler_top_left_x = coordinates[0][0]  # X-coordinate of the top-left corner\n",
    "ruler_top_left_y = coordinates[0][1]  # Y-coordinate of the top-left corner\n",
    "ruler_bottom_right_x = coordinates[1][0]  # X-coordinate of the bottom-right corner\n",
    "ruler_bottom_right_y = coordinates[1][1]  # Y-coordinate of the bottom-right corner\n",
    "\n",
    "# Extract the depth values within the ruler\n",
    "ruler_depth_values = depth_normalized[\n",
    "    ruler_top_left_y:ruler_bottom_right_y,\n",
    "    ruler_top_left_x:ruler_bottom_right_x\n",
    "]\n",
    "\n",
    "# Calculate the average depth within the ruler area\n",
    "ruler_depth_average = ruler_depth_values.max()\n",
    "\n",
    "# Print the average depth\n",
    "print(f\"Orange Area Depth: {ruler_depth_average}\")\n",
    "\n",
    "# # Display the heatmap\n",
    "# cv2.imshow('Depth Heatmap', depth_colormap)\n",
    "# cv2.imshow('Overlayed Heatmap', overlay)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange Area Actual Height: 0.355\n"
     ]
    }
   ],
   "source": [
    "oa_height_px = 71\n",
    "ruler_height_px = 200\n",
    "ruler_height_actual = 1\n",
    "oa_height_actual = (oa_height_px/ruler_height_px)*ruler_height_actual\n",
    "print(f\"Orange Area Actual Height: {oa_height_actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087308730873088"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Formula -> vessel_height_actual = vessel_height_px * (oa_height_actual/oa_height_px) * (vessel_depth/oa_depth)\n",
    "# oa_height_actual = 0.47\n",
    "# oa_height_px = 202\n",
    "# vessel_depth = 28.26\n",
    "# oa_depth = 33\n",
    "\n",
    "# vessel_height_actual = 120 * (oa_height_actual/rulerheight_px) * (depth_ship/depth_ruler)\n",
    "# vessel_height_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vhe_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
