{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "\n",
    "from PIL import Image\n",
    "#from dotenv import load_dotenv\n",
    "from scipy.ndimage import center_of_mass\n",
    "from src.third_party.depth_anything_v2.dpt import DepthAnythingV2\n",
    "from ultralytics import YOLO\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "image_path = 'outputs/K6xsEng2PhU/tracked_vehicles/vehicle_11_frame_475.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Height Estimation of Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse clicked at: (978, 503)\n",
      "Mouse clicked at: (979, 562)\n",
      "Clicked coordinates: [(978, 503), (979, 562)]\n",
      "Ruler Height in Pixels: 59\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a list to store the coordinates\n",
    "coordinates = []\n",
    "\n",
    "def get_coordinates(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Store the coordinates\n",
    "        coordinates.append((x, y))\n",
    "        print(f\"Mouse clicked at: ({x}, {y})\")\n",
    "\n",
    "# Specify the rotation angle in degrees (counterclockwise)\n",
    "rotation_angle = 0  # Replace with desired angle\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image.\")\n",
    "    exit()\n",
    "\n",
    "# Get image dimensions\n",
    "image_height, image_width = image.shape[:2]\n",
    "\n",
    "# Calculate the center of the image for rotation\n",
    "center = (image_width // 2, image_height // 2)\n",
    "\n",
    "# Compute the rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "\n",
    "# Determine the new bounding dimensions of the image after rotation\n",
    "cos = abs(rotation_matrix[0, 0])\n",
    "sin = abs(rotation_matrix[0, 1])\n",
    "new_width = int((image_height * sin) + (image_width * cos))\n",
    "new_height = int((image_height * cos) + (image_width * sin))\n",
    "\n",
    "# Adjust the rotation matrix to account for translation\n",
    "rotation_matrix[0, 2] += (new_width / 2) - center[0]\n",
    "rotation_matrix[1, 2] += (new_height / 2) - center[1]\n",
    "\n",
    "# Rotate the image\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (new_width, new_height))\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.namedWindow('Rotated Image')\n",
    "cv2.setMouseCallback('Rotated Image', get_coordinates)\n",
    "\n",
    "# Display the rotated image\n",
    "while True:\n",
    "    cv2.imshow('Rotated Image', rotated_image)\n",
    "    \n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print the clicked coordinates\n",
    "print(\"Clicked coordinates:\", coordinates)\n",
    "print(f\"Ruler Height in Pixels: {coordinates[1][1] - coordinates[0][1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth Estimation of Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruler Depth: 46.10896682739258\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "\n",
    "encoder = 'vitl'\n",
    "model = DepthAnythingV2(**model_configs[encoder])\n",
    "model.load_state_dict(torch.load(f'models_dav2/depth_anything_v2_{encoder}.pth', map_location='cuda'))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "raw_img = cv2.imread(image_path)\n",
    "\n",
    "# Rotate for better measurement of height\n",
    "rotation_angle = 0 # Counterclockwise rotation in degrees\n",
    "center = (raw_img.shape[1] // 2, raw_img.shape[0] // 2)  # Image center\n",
    "scale = 1.0  # No scaling\n",
    "\n",
    "# Compute the rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, scale)\n",
    "\n",
    "# Perform the rotation\n",
    "rotated_img = cv2.warpAffine(raw_img, rotation_matrix, (raw_img.shape[1], raw_img.shape[0]))\n",
    "depth = model.infer_image(raw_img)\n",
    "\n",
    "# Normalize depth map\n",
    "depth_normalized = (depth - depth.min()) / (depth.max() - depth.min()) * 255\n",
    "\n",
    "# Define the top-left and bottom-right coordinates of the rectangular area\n",
    "ruler_top_left_x = coordinates[0][0] # X-coordinate of the top-left corner\n",
    "ruler_top_left_y = coordinates[0][1]  # Y-coordinate of the top-left corner\n",
    "ruler_bottom_right_x = coordinates[1][0]  # X-coordinate of the bottom-right corner\n",
    "ruler_bottom_right_y = coordinates[1][1]  # Y-coordinate of the bottom-right corner\n",
    "\n",
    "# Extract the depth values within the ruler\n",
    "ruler_depth_values = depth_normalized[\n",
    "    ruler_top_left_y:ruler_bottom_right_y,\n",
    "    ruler_top_left_x:ruler_bottom_right_x\n",
    "]\n",
    "\n",
    "# Calculate the average depth within the ruler area\n",
    "ruler_depth_average = ruler_depth_values.mean()\n",
    "\n",
    "# Print the average depth\n",
    "print(f\"Ruler Depth: {ruler_depth_average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087308730873088"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formula -> vessel_height_actual = vessel_height_px * (ruler_height_actual/rulerheight_px) * (depth_ship/depth_ruler)\n",
    "ruler_height_actual = 1\n",
    "rulerheight_px = 202\n",
    "depth_ship = 28.26\n",
    "depth_ruler = 33\n",
    "\n",
    "vessel_height_actual = 120 * (ruler_height_actual/rulerheight_px) * (depth_ship/depth_ruler)\n",
    "vessel_height_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_vhe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
